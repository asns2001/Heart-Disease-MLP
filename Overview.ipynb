{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import train_test_split\n\n#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-23T00:48:39.624099Z","iopub.execute_input":"2022-04-23T00:48:39.625509Z","iopub.status.idle":"2022-04-23T00:48:40.823776Z","shell.execute_reply.started":"2022-04-23T00:48:39.624377Z","shell.execute_reply":"2022-04-23T00:48:40.823157Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"Import the data","metadata":{}},{"cell_type":"code","source":"# Reading datasets\ndf = pd.read_csv('../input/heart-disease-health-indicators-dataset/heart_disease_health_indicators_BRFSS2015.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:48:41.549803Z","iopub.execute_input":"2022-04-23T00:48:41.550164Z","iopub.status.idle":"2022-04-23T00:48:42.304949Z","shell.execute_reply.started":"2022-04-23T00:48:41.550127Z","shell.execute_reply":"2022-04-23T00:48:42.304272Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Data Exploration:","metadata":{}},{"cell_type":"code","source":"# Check value type & missing values \ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:31.574234Z","iopub.execute_input":"2022-04-21T05:10:31.57477Z","iopub.status.idle":"2022-04-21T05:10:31.59999Z","shell.execute_reply.started":"2022-04-21T05:10:31.574735Z","shell.execute_reply":"2022-04-21T05:10:31.599263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:33.897367Z","iopub.execute_input":"2022-04-21T05:10:33.897654Z","iopub.status.idle":"2022-04-21T05:10:34.166209Z","shell.execute_reply.started":"2022-04-21T05:10:33.897626Z","shell.execute_reply":"2022-04-21T05:10:34.165374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:37.366283Z","iopub.execute_input":"2022-04-21T05:10:37.366629Z","iopub.status.idle":"2022-04-21T05:10:37.371846Z","shell.execute_reply.started":"2022-04-21T05:10:37.366594Z","shell.execute_reply":"2022-04-21T05:10:37.371335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix to get a sense of the data\ncorr = df.corr()\nUpperT = np.triu(corr)\nplt.figure(figsize=(15,10))\nplt.title('Correlation Matrix')\nsns.heatmap(corr, mask=UpperT)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T20:21:38.596471Z","iopub.execute_input":"2022-04-22T20:21:38.597280Z","iopub.status.idle":"2022-04-22T20:21:39.569525Z","shell.execute_reply.started":"2022-04-22T20:21:38.597234Z","shell.execute_reply":"2022-04-22T20:21:39.568750Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Skew of numerical predictors\ndf.skew(axis = 0, skipna = True)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:42.020295Z","iopub.execute_input":"2022-04-21T05:10:42.02062Z","iopub.status.idle":"2022-04-21T05:10:42.133292Z","shell.execute_reply.started":"2022-04-21T05:10:42.020588Z","shell.execute_reply":"2022-04-21T05:10:42.132528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Duplicate dataset for anlaysis\ndf_copy = df.copy()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:43.482154Z","iopub.execute_input":"2022-04-21T05:10:43.482466Z","iopub.status.idle":"2022-04-21T05:10:43.505198Z","shell.execute_reply.started":"2022-04-21T05:10:43.482432Z","shell.execute_reply":"2022-04-21T05:10:43.504544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"idk why these are logged","metadata":{}},{"cell_type":"code","source":"# Log of Variables\ndf_copy['HeartDiseaseorAttack_Log'] = df_copy['HeartDiseaseorAttack'].apply(np.log)\ndf_copy['HighBP_Log'] = df_copy['HighBP'].apply(np.log)\ndf_copy['HighChol_Log'] = df_copy['HighChol'].apply(np.log) \ndf_copy['CholCheck_Log'] = df_copy['CholCheck'].apply(np.log) \ndf_copy['BMI_Log'] = df_copy['BMI'].apply(np.log)\ndf_copy['Smoker_Log'] = df_copy['Smoker'].apply(np.log)\ndf_copy['Diabetes_Log'] = df_copy['Diabetes'].apply(np.log)\ndf_copy['PhysActivity_Log'] = df_copy['PhysActivity'].apply(np.log)\ndf_copy['Fruits_Log'] = df_copy['Fruits'].apply(np.log)\ndf_copy['Veggies_Log'] = df_copy['Veggies'].apply(np.log) \ndf_copy['HvyAlcoholConsump_Log'] = df_copy['HvyAlcoholConsump'].apply(np.log) \ndf_copy['NoDocbcCost_Log'] = df_copy['NoDocbcCost'].apply(np.log)\ndf_copy['GenHlth_Log'] = df_copy['GenHlth'].apply(np.log)\ndf_copy['MentHlth_Log'] = df_copy['MentHlth'].apply(np.log) \ndf_copy['PhysHlth_Log'] = df_copy['PhysHlth'].apply(np.log) \ndf_copy['DiffWalk_Log'] = df_copy['DiffWalk'].apply(np.log)\ndf_copy['Sex_Log'] = df_copy['Sex'].apply(np.log)\ndf_copy['Age_Log'] = df_copy['Age'].apply(np.log)\ndf_copy['Education_Log'] = df_copy['Education'].apply(np.log)\ndf_copy['Income_Log'] = df_copy['Income'].apply(np.log)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:44.92698Z","iopub.execute_input":"2022-04-21T05:10:44.92739Z","iopub.status.idle":"2022-04-21T05:10:45.011735Z","shell.execute_reply.started":"2022-04-21T05:10:44.927348Z","shell.execute_reply":"2022-04-21T05:10:45.011121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting numerical features against sale price, and the corresponding log plot\nfig, ax = plt.subplots(18,2,figsize=(6,8))\nfig.suptitle('Numerical Features and Sale Price',size=20)\nsns.regplot(x = df_copy['HighBP'], y = df_copy['HeartDiseaseorAttack'], ax = ax[0,0])\nsns.regplot(x = df_copy['HighBP_Log'], y = df_copy['HeartDiseaseorAttack_Log'],ax = ax[0,1])\nsns.regplot(x = df_copy['HighChol'], y = df_copy['HeartDiseaseorAttack'], ax = ax[1,0])\nsns.regplot(x = df_copy['HighChol_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[1,1])\nsns.regplot(x = df_copy['CholCheck'], y = df_copy['HeartDiseaseorAttack'], ax = ax[2,0])\nsns.regplot(x = df_copy['CholCheck_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[2,1])\nsns.regplot(x = df_copy['BMI'], y = df_copy['HeartDiseaseorAttack'], ax = ax[3,0])\nsns.regplot(x = df_copy['BMI_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[3,1])\nsns.regplot(x = df_copy['Smoker'], y = df_copy['HeartDiseaseorAttack'], ax = ax[4,0])\nsns.regplot(x = df_copy['Smoker_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[4,1])\nsns.regplot(x = df_copy['Diabetes'], y = df_copy['HeartDiseaseorAttack'], ax = ax[5,0])\nsns.regplot(x = df_copy['Diabetes_Log'], y = df_copy['HeartDiseaseorAttack_Log'],ax = ax[5,1])\nsns.regplot(x = df_copy['PhysActivity'], y = df_copy['HeartDiseaseorAttack'], ax = ax[6,0])\nsns.regplot(x = df_copy['PhysActivity_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[6,1])\nsns.regplot(x = df_copy['Fruits'], y = df_copy['HeartDiseaseorAttack'], ax = ax[7,0])\nsns.regplot(x = df_copy['Fruits_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[7,1])\nsns.regplot(x = df_copy['Veggies'], y = df_copy['HeartDiseaseorAttack'], ax = ax[8,0])\nsns.regplot(x = df_copy['Veggies_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[8,1])\nsns.regplot(x = df_copy['HvyAlcoholConsump'], y = df_copy['HeartDiseaseorAttack'], ax = ax[9,0])\nsns.regplot(x = df_copy['HvyAlcoholConsump_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[9,1])\nsns.regplot(x = df_copy['NoDocbcCost'], y = df_copy['HeartDiseaseorAttack'], ax = ax[10,0])\nsns.regplot(x = df_copy['NoDocbcCost_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[10,1])\nsns.regplot(x = df_copy['GenHlth'], y = df_copy['HeartDiseaseorAttack'], ax = ax[11,0])\nsns.regplot(x = df_copy['GenHlth_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[11,1])\nsns.regplot(x = df_copy['MentHlth'], y = df_copy['HeartDiseaseorAttack'], ax = ax[12,0])\nsns.regplot(x = df_copy['MentHlth_Log'], y = df_copy['HeartDiseaseorAttack_Log'],ax = ax[12,1])\nsns.regplot(x = df_copy['PhysHlth'], y = df_copy['HeartDiseaseorAttack'], ax = ax[13,0])\nsns.regplot(x = df_copy['PhysHlth_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[13,1])\nsns.regplot(x = df_copy['DiffWalk'], y = df_copy['HeartDiseaseorAttack'], ax = ax[14,0])\nsns.regplot(x = df_copy['DiffWalk_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[14,1])\nsns.regplot(x = df_copy['Sex'], y = df_copy['HeartDiseaseorAttack'], ax = ax[15,0])\nsns.regplot(x = df_copy['Sex_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[15,1])\nsns.regplot(x = df_copy['Age'], y = df_copy['HeartDiseaseorAttack'], ax = ax[16,0])\nsns.regplot(x = df_copy['Age_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[16,1])\nsns.regplot(x = df_copy['Education'], y = df_copy['HeartDiseaseorAttack'], ax = ax[17,0])\nsns.regplot(x = df_copy['Education_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[17,1])\nsns.regplot(x = df_copy['Income'], y = df_copy['HeartDiseaseorAttack'], ax = ax[18,0])\nsns.regplot(x = df_copy['Income_Log'], y = df_copy['HeartDiseaseorAttack_Log'], ax = ax[18,1])","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:50.271451Z","iopub.execute_input":"2022-04-21T05:10:50.271852Z","iopub.status.idle":"2022-04-21T05:10:50.277386Z","shell.execute_reply.started":"2022-04-21T05:10:50.271823Z","shell.execute_reply":"2022-04-21T05:10:50.276713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing\n\n## Data Normalization\nAfter viewing all spreads of attributes we must:\n\nScale:\n* BMI\n* GenHlth\n* Age\n\nLog-scale\n* MentHlth - 6\n* PhysHlth\n* Education\n* Income","metadata":{}},{"cell_type":"code","source":"fig, axes = plt.subplots(3,2, figsize=(15,25))\n\nindex = 0\n\nbinary = [\"BMI\",\"GenHlth\",\"MentHlth\",\"PhysHlth\",\"Age\",\"Education\",\"Income\"]\n\nfor row in axes:\n  for col in row:\n    col.hist(df[binary[index]])\n    col.set_xlabel(binary[index])\n    index += 1\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:52.639206Z","iopub.execute_input":"2022-04-21T05:10:52.639542Z","iopub.status.idle":"2022-04-21T05:10:53.731296Z","shell.execute_reply.started":"2022-04-21T05:10:52.639507Z","shell.execute_reply":"2022-04-21T05:10:53.73045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"needs_logging = ['MentHlth', 'PhysHlth', 'Education', 'Income']\nneeds_normalization = ['BMI', 'GenHlth', 'Age']\n\nfor label in needs_logging:\n  df[label] = np.log2(df[label], where=df[label]!=0)\n\n  data = np.array(df[label]).reshape(-1,1)\n  scaler = StandardScaler()\n  scaler.fit(data)\n  data = scaler.transform(data)\n  df[label] = data.reshape(253680)\n\nfor label in needs_normalization:\n  data = np.array(df[label]).reshape(-1,1)\n  scaler = StandardScaler()\n  scaler.fit(data)\n  data = scaler.transform(data)\n  df[label] = data.reshape(253680)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:56.2814Z","iopub.execute_input":"2022-04-21T05:10:56.28166Z","iopub.status.idle":"2022-04-21T05:10:56.33021Z","shell.execute_reply.started":"2022-04-21T05:10:56.281632Z","shell.execute_reply":"2022-04-21T05:10:56.329579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var = 'GenHlth'\n\nplt.hist(df[var], color='blue')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:58.270983Z","iopub.execute_input":"2022-04-21T05:10:58.271284Z","iopub.status.idle":"2022-04-21T05:10:58.473128Z","shell.execute_reply.started":"2022-04-21T05:10:58.271248Z","shell.execute_reply":"2022-04-21T05:10:58.472243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation matrix to get a sense of the data\ncorr = df.corr()\nUpperT = np.triu(corr)\nplt.figure(figsize=(15,10))\nplt.title('Correlation Matrix')\nsns.heatmap(corr, mask=UpperT)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:10:59.774566Z","iopub.execute_input":"2022-04-21T05:10:59.775128Z","iopub.status.idle":"2022-04-21T05:11:00.824919Z","shell.execute_reply.started":"2022-04-21T05:10:59.77507Z","shell.execute_reply":"2022-04-21T05:11:00.823984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pie(labels, data):\n  a = np.array(data.value_counts())\n  plt.pie(a, labels=labels)\n  plt.show()\n  #axis.set_xlabel(label)\n\n#fig, axes = plt.subplots(7,2, figsize=(15,50))\n\n\nindex = 0\n\nbinary = [\"HeartDiseaseorAttack\",\"HighBP\",\"HighChol\",\"CholCheck\",\"Smoker\",\"Diabetes\",\"PhysActivity\",\"Fruits\",\"Veggies\",\"HvyAlcoholConsump\",\"AnyHealthcare\",\"NoDocbcCost\",\"DiffWalk\",\"Sex\"]\n\npie([\"None\",\"HeartDiseaseorAttack\"], df[\"HeartDiseaseorAttack\"])\npie([\"LowBP\",\"HighBP\"], df[\"HighBP\"])\npie([\"LowChol\",\"HighChol\"], df[\"HighChol\"])\npie([\"Not\",\"Checked\"], df[\"CholCheck\"])\npie([\"Not\",\"Smoker\"], df[\"Smoker\"])\npie([\"Not\",\"Pre-Diabetic\",\"Diabetic\"], df[\"Diabetes\"])\npie([\"Not\",\"PhysActivity\"], df[\"PhysActivity\"])\npie([\"No\",\"Fruits\"], df[\"Fruits\"])\npie([\"No\",\"Veggies\"], df[\"Veggies\"])\npie([\"No\",\"HvyAlcoholConsump\"], df[\"HvyAlcoholConsump\"])\npie([\"No\",\"AnyHealthcare\"], df[\"AnyHealthcare\"])\npie([\"No\",\"NoDocbcCost\"], df[\"NoDocbcCost\"])\npie([\"No\",\"DiffWalk\"], df[\"DiffWalk\"])\npie([\"Female\",\"Male\"], df[\"Sex\"])\n\n#fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:12:25.185878Z","iopub.execute_input":"2022-04-21T05:12:25.186173Z","iopub.status.idle":"2022-04-21T05:12:27.00752Z","shell.execute_reply.started":"2022-04-21T05:12:25.186142Z","shell.execute_reply":"2022-04-21T05:12:27.006334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(3,2, figsize=(15,25))\n\nindex = 0\n\nbinary = [\"BMI\",\"GenHlth\",\"MentHlth\",\"PhysHlth\",\"Age\",\"Education\",\"Income\"]\n\nfor row in axes:\n  for col in row:\n    col.hist(df[binary[index]])\n    col.set_xlabel(binary[index])\n    index += 1\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-21T05:12:43.118158Z","iopub.execute_input":"2022-04-21T05:12:43.118469Z","iopub.status.idle":"2022-04-21T05:12:44.146232Z","shell.execute_reply.started":"2022-04-21T05:12:43.118428Z","shell.execute_reply":"2022-04-21T05:12:44.145382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mine","metadata":{}},{"cell_type":"markdown","source":"# Splitting the Data","metadata":{}},{"cell_type":"code","source":"y = df['HeartDiseaseorAttack']  # Labels\nX = df.drop(['HeartDiseaseorAttack'],axis=1)  # Features\n\nprint(y.shape, X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:03:03.493890Z","iopub.execute_input":"2022-04-22T19:03:03.494217Z","iopub.status.idle":"2022-04-22T19:03:03.517762Z","shell.execute_reply.started":"2022-04-22T19:03:03.494184Z","shell.execute_reply":"2022-04-22T19:03:03.516948Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"print(\"Total data points:\", len(df['HeartDiseaseorAttack']))\nprint(\"# of data points that are positive for Heart Disease:\", len(df[df['HeartDiseaseorAttack'] == 1]))\n\nprint(\"% of data points that are positive for Heart Disease:\", len(df['HeartDiseaseorAttack'])/len(df[df['HeartDiseaseorAttack'] == 1]))\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T18:41:53.620993Z","iopub.execute_input":"2022-04-22T18:41:53.621440Z","iopub.status.idle":"2022-04-22T18:41:53.640409Z","shell.execute_reply.started":"2022-04-22T18:41:53.621392Z","shell.execute_reply":"2022-04-22T18:41:53.639848Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training set and test set\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) # 70% training and 30% test","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:03:04.995221Z","iopub.execute_input":"2022-04-22T19:03:04.996042Z","iopub.status.idle":"2022-04-22T19:03:05.063840Z","shell.execute_reply.started":"2022-04-22T19:03:04.995997Z","shell.execute_reply":"2022-04-22T19:03:05.062926Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"markdown","source":"Splitting data into training, testing and validation data sets","metadata":{}},{"cell_type":"code","source":"train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df, val_df = train_test_split(train_df, test_size=0.2)\n\n# Form np arrays of labels and features.\ntrain_labels = np.array(train_df.pop('HeartDiseaseorAttack'))\nbool_train_labels = train_labels != 0\nval_labels = np.array(val_df.pop('HeartDiseaseorAttack'))\ntest_labels = np.array(test_df.pop('HeartDiseaseorAttack'))\n\ntrain_features = np.array(train_df)\nval_features = np.array(val_df)\ntest_features = np.array(test_df)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:49:36.285181Z","iopub.execute_input":"2022-04-23T00:49:36.285695Z","iopub.status.idle":"2022-04-23T00:49:36.418343Z","shell.execute_reply.started":"2022-04-23T00:49:36.285666Z","shell.execute_reply":"2022-04-23T00:49:36.417640Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model 1: Random Forest\n\n## Model 1A","metadata":{}},{"cell_type":"code","source":"#Import Random Forest Model\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf = RandomForestClassifier(n_estimators=100)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(train_features,train_labels)\n\nval_pred = clf.predict(val_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:51:23.084485Z","iopub.execute_input":"2022-04-23T00:51:23.084857Z","iopub.status.idle":"2022-04-23T00:51:45.458879Z","shell.execute_reply.started":"2022-04-23T00:51:23.084835Z","shell.execute_reply":"2022-04-23T00:51:45.457790Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(val_labels, val_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:51:45.461349Z","iopub.execute_input":"2022-04-23T00:51:45.461710Z","iopub.status.idle":"2022-04-23T00:51:45.473112Z","shell.execute_reply.started":"2022-04-23T00:51:45.461671Z","shell.execute_reply":"2022-04-23T00:51:45.471990Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Model 1B","metadata":{}},{"cell_type":"code","source":"clf_2 = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n            max_depth=None, max_features='auto', max_leaf_nodes=None,\n            min_impurity_decrease=0.0,\n            min_samples_leaf=1, min_samples_split=2,\n            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n            oob_score=False, random_state=None, verbose=0,\n            warm_start=False)\n\nclf_2.fit(train_features,train_labels)\n\nval_pred = clf_2.predict(val_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:54:23.217432Z","iopub.execute_input":"2022-04-23T00:54:23.217656Z","iopub.status.idle":"2022-04-23T00:54:45.325053Z","shell.execute_reply.started":"2022-04-23T00:54:23.217634Z","shell.execute_reply":"2022-04-23T00:54:45.323574Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(val_labels, val_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:54:45.327772Z","iopub.execute_input":"2022-04-23T00:54:45.328079Z","iopub.status.idle":"2022-04-23T00:54:45.338175Z","shell.execute_reply.started":"2022-04-23T00:54:45.328048Z","shell.execute_reply":"2022-04-23T00:54:45.337361Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Model 1C","metadata":{}},{"cell_type":"code","source":"clf_3 = RandomForestClassifier(\n                          n_estimators = 100,\n                          criterion = 'gini',\n                          max_depth = 100\n                          )\n\nclf_3.fit(train_features,train_labels)\n\nval_pred = clf_3.predict(val_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:54:45.339630Z","iopub.execute_input":"2022-04-23T00:54:45.340397Z","iopub.status.idle":"2022-04-23T00:55:07.773142Z","shell.execute_reply.started":"2022-04-23T00:54:45.340365Z","shell.execute_reply":"2022-04-23T00:55:07.772217Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(val_labels, val_pred))","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:55:07.774755Z","iopub.execute_input":"2022-04-23T00:55:07.774969Z","iopub.status.idle":"2022-04-23T00:55:07.785053Z","shell.execute_reply.started":"2022-04-23T00:55:07.774944Z","shell.execute_reply":"2022-04-23T00:55:07.784280Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection: \n\nThe 2nd model was the best model, so we used it to do feature analysis:","metadata":{}},{"cell_type":"code","source":"# Feature Names \nfeature_names = list(df.columns[1:])\n\nprint(clf_2.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:57:33.208052Z","iopub.execute_input":"2022-04-23T00:57:33.208559Z","iopub.status.idle":"2022-04-23T00:57:33.267584Z","shell.execute_reply.started":"2022-04-23T00:57:33.208527Z","shell.execute_reply":"2022-04-23T00:57:33.266935Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"feature_imp = pd.Series(clf_2.feature_importances_,index = feature_names).sort_values(ascending=False)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n# Creating a bar plot\nsns.barplot(x = feature_imp, y = feature_imp.index)\n# Add labels to your graph\nplt.xlabel('Feature Importance Score')\nplt.ylabel('Features')\nplt.title(\"Visualizing Important Features\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-23T00:57:35.622914Z","iopub.execute_input":"2022-04-23T00:57:35.623340Z","iopub.status.idle":"2022-04-23T00:57:36.015278Z","shell.execute_reply.started":"2022-04-23T00:57:35.623312Z","shell.execute_reply":"2022-04-23T00:57:36.014359Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"note: Missing the end of (https://colab.research.google.com/drive/16Zsdep7fXweskNsDAloUfumGVd2o6Zur#scrollTo=z1OSLQNDCJ8B) where the new model doesn't perform well","metadata":{}},{"cell_type":"markdown","source":"# MLP Models","metadata":{}},{"cell_type":"markdown","source":"## Apply PCA","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\n# Fit on training set only.\nscaler.fit(train_features)\n\n# Fitting for PCA Visualization\ndata_rescaled = scaler.fit(df)\n\n# Apply transform to both the training set and the test set.\ntrain_features = scaler.transform(train_features)\nval_features = scaler.transform(val_features)\ntest_features = scaler.transform(test_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:03:09.527590Z","iopub.execute_input":"2022-04-22T19:03:09.528082Z","iopub.status.idle":"2022-04-22T19:03:09.671172Z","shell.execute_reply.started":"2022-04-22T19:03:09.528044Z","shell.execute_reply":"2022-04-22T19:03:09.670259Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA().fit(data_rescaled)\n\nimport matplotlib.pyplot as plt\nplt.rcParams[\"figure.figsize\"] = (12,6)\n\nfig, ax = plt.subplots()\nxi = np.arange(1, 23, step=1)\ny = np.cumsum(pca.explained_variance_ratio_)\n\nplt.ylim(0.0,1.1)\nplt.plot(xi, y, marker='o', linestyle='--', color='b')\n\nplt.xlabel('Number of Components')\nplt.xticks(np.arange(0, 23, step=1)) #change from 0-based array index to 1-based human-readable label\nplt.ylabel('Cumulative variance (%)')\nplt.title('The number of components needed to explain variance')\n\nplt.axhline(y=0.95, color='r', linestyle='-')\nplt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n\nax.grid(axis='x')\nplt.show()\n\n#https://www.mikulskibartosz.name/pca-how-to-choose-the-number-of-components/","metadata":{"execution":{"iopub.status.busy":"2022-04-22T18:58:24.723338Z","iopub.execute_input":"2022-04-22T18:58:24.723878Z","iopub.status.idle":"2022-04-22T18:58:25.346834Z","shell.execute_reply.started":"2022-04-22T18:58:24.723843Z","shell.execute_reply":"2022-04-22T18:58:25.345948Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components = 0.95)\n\npca.fit(train_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:04:08.301468Z","iopub.execute_input":"2022-04-22T19:04:08.302136Z","iopub.status.idle":"2022-04-22T19:04:08.306647Z","shell.execute_reply.started":"2022-04-22T19:04:08.302088Z","shell.execute_reply":"2022-04-22T19:04:08.305695Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"# print the explained variances\nprint(\"Variances (Percentage):\")\nprint(pca.explained_variance_ratio_ * 100)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:04:13.634282Z","iopub.execute_input":"2022-04-22T19:04:13.635070Z","iopub.status.idle":"2022-04-22T19:04:13.640672Z","shell.execute_reply.started":"2022-04-22T19:04:13.635024Z","shell.execute_reply":"2022-04-22T19:04:13.639468Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"print(\"Cumulative Variances (Percentage):\")\nprint(pca.explained_variance_ratio_.cumsum() * 100)\nprint()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:04:25.483033Z","iopub.execute_input":"2022-04-22T19:04:25.483335Z","iopub.status.idle":"2022-04-22T19:04:25.489232Z","shell.execute_reply.started":"2022-04-22T19:04:25.483301Z","shell.execute_reply":"2022-04-22T19:04:25.488257Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"# plot a scree plot\ncomponents = len(pca.explained_variance_ratio_)\nplt.plot(range(1,components+1), \n         np.cumsum(pca.explained_variance_ratio_ * 100))\nplt.xlabel(\"Number of components\")\nplt.ylabel(\"Explained variance (%)\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:05:00.126495Z","iopub.execute_input":"2022-04-22T19:05:00.126865Z","iopub.status.idle":"2022-04-22T19:05:00.366202Z","shell.execute_reply.started":"2022-04-22T19:05:00.126831Z","shell.execute_reply":"2022-04-22T19:05:00.365574Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"pca = PCA(n_components = 0.95)\npca.fit(train_features)\n\nprint(\"Cumulative Variances (Percentage):\")\nprint(np.cumsum(pca.explained_variance_ratio_ * 100))\n\ncomponents = len(pca.explained_variance_ratio_)\nprint(f'Number of components: {components}')\n\n# Make the scree plot\nplt.plot(range(1, components + 1), np.cumsum(pca.explained_variance_ratio_ * 100))\nplt.xlabel(\"Number of components\")\nplt.ylabel(\"Explained variance (%)\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T19:06:11.021498Z","iopub.execute_input":"2022-04-22T19:06:11.021961Z","iopub.status.idle":"2022-04-22T19:06:11.471017Z","shell.execute_reply.started":"2022-04-22T19:06:11.021926Z","shell.execute_reply":"2022-04-22T19:06:11.469697Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"train_features = pca.transform(train_features)\nval_features = pca.transform(val_features)\ntest_features = pca.transform(test_features)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T18:48:25.336470Z","iopub.execute_input":"2022-04-22T18:48:25.336726Z","iopub.status.idle":"2022-04-22T18:48:25.376008Z","shell.execute_reply.started":"2022-04-22T18:48:25.336687Z","shell.execute_reply":"2022-04-22T18:48:25.375056Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# visualizing pca\nprincipalComponents = pca.fit_transform(X)\n# principalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2'])\n# principalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10','PC11','PC12','PC13','PC14','PC15','PC16','PC17'])\nprincipalDataframe = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2','PC3','PC4'])\n\n\n# Combine the Target and the Principal Components\ntargetDataframe = df[[\"HeartDiseaseorAttack\"]]\n\nnewDataframe = pd.concat([principalDataframe, targetDataframe],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:32:51.752613Z","iopub.execute_input":"2022-04-22T17:32:51.753195Z","iopub.status.idle":"2022-04-22T17:32:51.987400Z","shell.execute_reply.started":"2022-04-22T17:32:51.753144Z","shell.execute_reply":"2022-04-22T17:32:51.986366Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n# plt.scatter(principalDataframe.PC1, principalDataframe.PC2, principalDataframe.PC3, principalDataframe.PC4,, principalDataframe.PC5, principalDataframe.PC6, principalDataframe.PC7, principalDataframe.PC8, principalDataframe.PC9, principalDataframe.PC10, principalDataframe.PC11, principalDataframe.PC12, principalDataframe.PC13, principalDataframe.PC14, principalDataframe.PC15, principalDataframe.PC16, principalDataframe.PC17)\nplt.scatter(principalDataframe.PC1, principalDataframe.PC2)\nplt.title('PC1 against PC2')\nplt.xlabel('PC1')\nplt.ylabel('PC2')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:33:40.127747Z","iopub.execute_input":"2022-04-22T17:33:40.128075Z","iopub.status.idle":"2022-04-22T17:33:41.223403Z","shell.execute_reply.started":"2022-04-22T17:33:40.128041Z","shell.execute_reply":"2022-04-22T17:33:41.222330Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (8,8))\nax = fig.add_subplot(1,1,1) \nax.set_xlabel('PC1')\nax.set_ylabel('PC2')\n\nax.set_title('Plot of PC1 vs PC2', fontsize = 20)\n\ntargets = [0, 1]\n\ncolors = ['g', 'r']\n\nfor target, color in zip(targets,colors):\n    indicesToKeep = newDataframe['HeartDiseaseorAttack'] == target\n    ax.scatter(newDataframe.loc[indicesToKeep, 'PC2']\n               , newDataframe.loc[indicesToKeep, 'PC4']\n               , c = color\n               , s = 50)\n    \nax.legend(targets)\nax.grid()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T17:35:14.445440Z","iopub.execute_input":"2022-04-22T17:35:14.446043Z","iopub.status.idle":"2022-04-22T17:35:17.873373Z","shell.execute_reply.started":"2022-04-22T17:35:14.445996Z","shell.execute_reply":"2022-04-22T17:35:17.872226Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# MLP Model","metadata":{}},{"cell_type":"markdown","source":"### Basic Model","metadata":{}},{"cell_type":"code","source":"#Basic Model:\nann = tf.keras.models.Sequential()\nann.add(tf.keras.layers.Dense(32, input_dim=21, kernel_regularizer=l2(0.01), activation='relu', input_shape=train_features[0].shape))\nann.add(tf.keras.layers.Dense(16, input_dim=16, kernel_regularizer=l2(0.01), activation='relu'))\nann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\nann.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\nann.fit(train_features, train_labels, batch_size = 4, epochs = 10)\n\n# training accyracy = 90.73 (got better from 1 - 10)\n# testing accuracy - 90.74","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann1.evaluate(train_features, train_labels,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ann1.evaluate(val_features, val_labels)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn.metrics\ntrain_pred = ann1.predict(train_features) \n\nimport numpy as np\ntrain_pred_r = np.rint(train_pred)\n\ncf_matrix = sklearn.metrics.confusion_matrix(train_labels, train_pred_r)\n\nprint(cf_matrix)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Improved Model:","metadata":{}},{"cell_type":"code","source":"METRICS = [\n      keras.metrics.TruePositives(name='tp'),\n      keras.metrics.FalsePositives(name='fp'),\n      keras.metrics.TrueNegatives(name='tn'),\n      keras.metrics.FalseNegatives(name='fn'), \n      keras.metrics.BinaryAccuracy(name='accuracy'),\n      keras.metrics.Precision(name='precision'),\n      keras.metrics.Recall(name='recall'),\n      keras.metrics.AUC(name='auc'),\n      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n]\n\ndef make_model(number_of_hidden_layers=1, activation_function='relu', final_activation_function='sigmoid', learning_rate=1e-3):\n  layers = [keras.layers.Dense(\n          16, activation='relu',\n          input_shape=(train_features.shape[-1],))]\n  for layer in range(number_of_hidden_layers):\n    layers.append(keras.layers.Dense(16, input_dim=16, activation=activation_function))\n\n  layers.append(keras.layers.Dropout(0.5))\n  layers.append(keras.layers.Dense(1, activation=final_activation_function))\n\n  model = keras.Sequential(layers)\n\n  model.compile(\n      optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=METRICS)\n\n  return model\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 100 \nBATCH_SIZE = 2048 \n\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_prc', \n    verbose=1,\n    patience=10,\n    mode='max',\n    restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:41:56.941807Z","iopub.execute_input":"2022-04-22T02:41:56.942075Z","iopub.status.idle":"2022-04-22T02:42:01.692281Z","shell.execute_reply.started":"2022-04-22T02:41:56.942047Z","shell.execute_reply":"2022-04-22T02:42:01.690619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:42:01.693615Z","iopub.execute_input":"2022-04-22T02:42:01.69386Z","iopub.status.idle":"2022-04-22T02:43:25.533645Z","shell.execute_reply.started":"2022-04-22T02:42:01.693831Z","shell.execute_reply":"2022-04-22T02:43:25.532767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos_features = train_features[bool_train_labels]\nneg_features = train_features[~bool_train_labels]\n\npos_labels = train_labels[bool_train_labels]\nneg_labels = train_labels[~bool_train_labels]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T06:12:01.091932Z","iopub.execute_input":"2022-04-21T06:12:01.092869Z","iopub.status.idle":"2022-04-21T06:12:10.486071Z","shell.execute_reply.started":"2022-04-21T06:12:01.092825Z","shell.execute_reply":"2022-04-21T06:12:10.485209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = np.arange(len(pos_features))\nchoices = np.random.choice(ids, len(neg_features))\n\nres_pos_features = pos_features[choices]\nres_pos_labels = pos_labels[choices]\n\nres_pos_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-22T02:45:29.019097Z","iopub.execute_input":"2022-04-22T02:45:29.019413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\nresampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n\norder = np.arange(len(resampled_labels))\nnp.random.shuffle(order)\nresampled_features = resampled_features[order]\nresampled_labels = resampled_labels[order]\n\nresampled_features.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-21T06:31:42.295171Z","iopub.status.idle":"2022-04-21T06:31:42.29625Z","shell.execute_reply.started":"2022-04-21T06:31:42.295946Z","shell.execute_reply":"2022-04-21T06:31:42.295976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = 100000\n\ndef make_ds(features, labels):\n  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n  ds = ds.shuffle(BUFFER_SIZE).repeat()\n  return ds\n\npos_ds = make_ds(pos_features, pos_labels)\nneg_ds = make_ds(neg_features, neg_labels)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T06:31:42.297767Z","iopub.status.idle":"2022-04-21T06:31:42.298491Z","shell.execute_reply.started":"2022-04-21T06:31:42.298164Z","shell.execute_reply":"2022-04-21T06:31:42.298197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\nresampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pos = len(df[df[\"HeartDiseaseorAttack\"] == 1])\nneg = len(df[df[\"HeartDiseaseorAttack\"] == 0])\n\nresampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\nresampled_steps_per_epoch","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_model(number_of_hidden_layers=1)\n\nval_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n\nresampled_history = model.fit(\n    resampled_ds,\n    epochs=EPOCHS,\n    steps_per_epoch=resampled_steps_per_epoch,\n    callbacks=[early_stopping],\n    validation_data=val_ds)\n\ninitial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\nmodel.save_weights('initial_weights')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"activations = ['relu', 'sigmoid', 'softmax']\nrates = [1e-2,1e-3,1e-4]\n\nresults = {}\n\nfor activation_function in activations:\n  results[activation_function] = []\n  for learning_rate in rates:\n    model = make_model(number_of_hidden_layers=1, activation_function=activation_function, learning_rate=learning_rate)\n    model.load_weights('initial_weights')\n\n    val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n    val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n\n    resampled_history = model.fit(\n        resampled_ds,\n        epochs=EPOCHS,\n        steps_per_epoch=resampled_steps_per_epoch,\n        callbacks=[early_stopping],\n        validation_data=val_ds)\n    \n    res = {'rec':0,'acc':0}\n    res['rec'] = max(resampled_history.history[\"val_recall\"])\n    res['acc'] = max(resampled_history.history[\"val_accuracy\"])\n    \n    results[activation_function].append(res)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model():\n  layers = [keras.layers.Dense(16, activation='relu',input_shape=(train_features.shape[-1],)),\n          keras.layers.Dense(16, input_dim=16, activation='relu'),\n          keras.layers.Dropout(0.5),\n          keras.layers.Dense(1, activation='sigmoid')]\n\n  model = keras.Sequential(layers)\n\n  model.compile(\n      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n      loss=keras.losses.BinaryCrossentropy(),\n      metrics=METRICS)\n\n  return model\n\nmodel = make_model()\nmodel.summary()\n\nval_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\nval_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n\nresampled_history = model.fit(\n    resampled_ds,\n    epochs=EPOCHS,\n    steps_per_epoch=resampled_steps_per_epoch,\n    callbacks=[early_stopping],\n    validation_data=val_ds)","metadata":{},"execution_count":null,"outputs":[]}]}