{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAIXYQZJyz9K"
      },
      "source": [
        "# Library and data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng4oyEGKek7h"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NuWI1BtiXouA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"heart_indicators_clean.csv\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYQ9RcM2iUO7"
      },
      "source": [
        "# Data Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gQkNAW_6iWWp"
      },
      "outputs": [],
      "source": [
        "#drop_these = ['Fruits','Veggies','CholCheck','BMI','PhysActivity','HvyAlcoholConsump','AnyHealthcare','NoDocbcCost','MentHlth','Sex','Education']\n",
        "df_imp = df.copy()\n",
        "#for label in drop_these:\n",
        "#  df_imp = df_imp.drop(label, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UOpNOx-WehDj",
        "outputId": "595e3b41-1dcd-46b8-f2e1-4426e7fefba3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['HeartDiseaseorAttack', 'HighBP', 'HighChol', 'CholCheck', 'BMI',\n",
              "       'Smoker', 'Stroke', 'Diabetes', 'PhysActivity', 'Fruits', 'Veggies',\n",
              "       'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth',\n",
              "       'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education',\n",
              "       'Income'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_imp.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXXY11HbycR"
      },
      "source": [
        "# ANN Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2viiewfTSdv4"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df_imp, test_size=0.2)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('HeartDiseaseorAttack'))\n",
        "bool_train_labels = train_labels != 0\n",
        "val_labels = np.array(val_df.pop('HeartDiseaseorAttack'))\n",
        "test_labels = np.array(test_df.pop('HeartDiseaseorAttack'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "val_features = np.array(val_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TT7cdjIlb0QZ"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "      keras.metrics.TruePositives(name='tp'),\n",
        "      keras.metrics.FalsePositives(name='fp'),\n",
        "      keras.metrics.TrueNegatives(name='tn'),\n",
        "      keras.metrics.FalseNegatives(name='fn'), \n",
        "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "def make_model(metrics=METRICS, output_bias=None):\n",
        "  if output_bias is not None:\n",
        "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
        "  model = keras.Sequential([\n",
        "      keras.layers.Dense(\n",
        "          16, activation='relu',\n",
        "          input_shape=(train_features.shape[-1],)),\n",
        "      keras.layers.Dense(32, input_dim=16, activation='relu'),\n",
        "      keras.layers.Dense(16, input_dim=32, activation='relu'),\n",
        "      keras.layers.Dropout(0.5),\n",
        "      keras.layers.Dense(1, activation='sigmoid',\n",
        "                         bias_initializer=output_bias),\n",
        "  ])\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "      loss=keras.losses.BinaryCrossentropy(),\n",
        "      metrics=metrics)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ee43IUAnSyYr"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 2048\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_prc', \n",
        "    verbose=1,\n",
        "    patience=10,\n",
        "    mode='max',\n",
        "    restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oa9yJf5bS1IR",
        "outputId": "2d410612-5fb2-4a55-995d-5ca1325e167e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 16)                352       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,441\n",
            "Trainable params: 1,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = make_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_fZEl4-HS9AY",
        "outputId": "88503e75-5759-4191-9eff-2a031370bf96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.11993334],\n",
              "       [0.14878783],\n",
              "       [0.11928332],\n",
              "       [0.14582333],\n",
              "       [0.15159526],\n",
              "       [0.14785469],\n",
              "       [0.10784417],\n",
              "       [0.15503943],\n",
              "       [0.14944494],\n",
              "       [0.12232849]], dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M6-4yB7TEVmT",
        "outputId": "a1ffcc59-c1a0-4b9e-b1a3-952cbc5d668b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-2.26356726]\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "x = len(df['HeartDiseaseorAttack'])\n",
        "y = len(df[df['HeartDiseaseorAttack'] == 1])\n",
        "print(y/x)\n",
        "\n",
        "print(len(df['HeartDiseaseorAttack']))\n",
        "print(len(df[df['HeartDiseaseorAttack'] == 1]))\n",
        "'''\n",
        "pos = 23893\n",
        "neg = 253680-pos\n",
        "initial_bias = np.log([pos/(neg)])\n",
        "print(initial_bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5D8MEVsDEQGF",
        "outputId": "0951535b-6885-4a0b-8e05-18efd3d4db7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.08331007],\n",
              "       [0.09124753],\n",
              "       [0.0745329 ],\n",
              "       [0.0961476 ],\n",
              "       [0.08497512],\n",
              "       [0.08858493],\n",
              "       [0.07870594],\n",
              "       [0.09688026],\n",
              "       [0.09758708],\n",
              "       [0.09133032]], dtype=float32)"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = make_model(output_bias=initial_bias)\n",
        "model.predict(train_features[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKkn9eh_b_vh"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
        "print(\"Loss: {:0.4f}\".format(results[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVPlgbnB4nCj"
      },
      "outputs": [],
      "source": [
        "initial_weights = os.path.join(tempfile.mkdtemp(), 'initial_weights')\n",
        "model.save_weights(initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNNSvNc_TdHE"
      },
      "outputs": [],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "model.layers[-1].bias.assign([0.0])\n",
        "zero_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SdbfBM-TixD"
      },
      "outputs": [],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "careful_bias_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=(val_features, val_labels), \n",
        "    verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnXuh3PcTl0B"
      },
      "outputs": [],
      "source": [
        "colors = ['r','b']\n",
        "\n",
        "def plot_loss(history, label, n):\n",
        "  # Use a log scale on y-axis to show the wide range of values.\n",
        "  plt.semilogy(history.epoch, history.history['loss'],\n",
        "               color=colors[n], label='Train ' + label)\n",
        "  plt.semilogy(history.epoch, history.history['val_loss'],\n",
        "               color=colors[n], label='Val ' + label,\n",
        "               linestyle=\"--\")\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mm-Rr89TnQ7"
      },
      "outputs": [],
      "source": [
        "plot_loss(zero_bias_history, \"Zero Bias\", 0)\n",
        "plot_loss(careful_bias_history, \"Careful Bias\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp7RyonCT3kz"
      },
      "outputs": [],
      "source": [
        "model = make_model()\n",
        "model.load_weights(initial_weights)\n",
        "baseline_history = model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xOtQG19T_tw"
      },
      "outputs": [],
      "source": [
        "def plot_metrics(history):\n",
        "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
        "  for n, metric in enumerate(metrics):\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\n",
        "    plt.subplot(2,2,n+1)\n",
        "    plt.plot(history.epoch, history.history[metric], color=colors[0], label='Train')\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\n",
        "             color=colors[0], linestyle=\"--\", label='Val')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel(name)\n",
        "    if metric == 'loss':\n",
        "      plt.ylim([0, plt.ylim()[1]])\n",
        "    elif metric == 'auc':\n",
        "      plt.ylim([0.8,1])\n",
        "    else:\n",
        "      plt.ylim([0,1])\n",
        "\n",
        "    plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_9fapn8UBdo"
      },
      "outputs": [],
      "source": [
        "plot_metrics(baseline_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgBm0D7RUGth"
      },
      "outputs": [],
      "source": [
        "train_predictions_baseline = model.predict(train_features, batch_size=BATCH_SIZE)\n",
        "test_predictions_baseline = model.predict(test_features, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfvXf3KDUIIS"
      },
      "outputs": [],
      "source": [
        "def plot_cm(labels, predictions, p=0.5):\n",
        "  cm = confusion_matrix(labels, predictions > p)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
        "  plt.ylabel('Actual label')\n",
        "  plt.xlabel('Predicted label')\n",
        "\n",
        "  print('Legitimate Transactions Detected (True Negatives): ', cm[0][0])\n",
        "  print('Legitimate Transactions Incorrectly Detected (False Positives): ', cm[0][1])\n",
        "  print('Fraudulent Transactions Missed (False Negatives): ', cm[1][0])\n",
        "  print('Fraudulent Transactions Detected (True Positives): ', cm[1][1])\n",
        "  print('Total Fraudulent Transactions: ', np.sum(cm[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBnS3tONUJRc"
      },
      "outputs": [],
      "source": [
        "def plot_roc(name, labels, predictions, **kwargs):\n",
        "  fp, tp, _ = sklearn.metrics.roc_curve(labels, predictions)\n",
        "\n",
        "  plt.plot(100*fp, 100*tp, label=name, linewidth=2, **kwargs)\n",
        "  plt.xlabel('False positives [%]')\n",
        "  plt.ylabel('True positives [%]')\n",
        "  plt.xlim([-0.5,20])\n",
        "  plt.ylim([80,100.5])\n",
        "  plt.grid(True)\n",
        "  ax = plt.gca()\n",
        "  ax.set_aspect('equal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inFJvfiPUd_e"
      },
      "outputs": [],
      "source": [
        "# Scaling by total/2 helps keep the loss to a similar magnitude.\n",
        "# The sum of the weights of all examples stays the same.\n",
        "weight_for_0 = (1 / neg) * ((pos+neg) / 2.0)\n",
        "weight_for_1 = (1 / pos) * ((pos+neg) / 2.0)\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQJbDUvDVAkk"
      },
      "outputs": [],
      "source": [
        "weighted_model = make_model()\n",
        "weighted_model.load_weights(initial_weights)\n",
        "\n",
        "weighted_history = weighted_model.fit(\n",
        "    train_features,\n",
        "    train_labels,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=(val_features, val_labels),\n",
        "    # The class weights go here\n",
        "    class_weight=class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrMTmQX5VG3s"
      },
      "outputs": [],
      "source": [
        "plot_metrics(weighted_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHnTA6hwVuS0"
      },
      "outputs": [],
      "source": [
        "pos_features = train_features[bool_train_labels]\n",
        "neg_features = train_features[~bool_train_labels]\n",
        "\n",
        "pos_labels = train_labels[bool_train_labels]\n",
        "neg_labels = train_labels[~bool_train_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEa_qYAvVvuk"
      },
      "outputs": [],
      "source": [
        "ids = np.arange(len(pos_features))\n",
        "choices = np.random.choice(ids, len(neg_features))\n",
        "\n",
        "res_pos_features = pos_features[choices]\n",
        "res_pos_labels = pos_labels[choices]\n",
        "\n",
        "res_pos_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WajlQ7OEVw_e"
      },
      "outputs": [],
      "source": [
        "resampled_features = np.concatenate([res_pos_features, neg_features], axis=0)\n",
        "resampled_labels = np.concatenate([res_pos_labels, neg_labels], axis=0)\n",
        "\n",
        "order = np.arange(len(resampled_labels))\n",
        "np.random.shuffle(order)\n",
        "resampled_features = resampled_features[order]\n",
        "resampled_labels = resampled_labels[order]\n",
        "\n",
        "resampled_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfsaWnkKVydG"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = 100000\n",
        "\n",
        "def make_ds(features, labels):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((features, labels))#.cache()\n",
        "  ds = ds.shuffle(BUFFER_SIZE).repeat()\n",
        "  return ds\n",
        "\n",
        "pos_ds = make_ds(pos_features, pos_labels)\n",
        "neg_ds = make_ds(neg_features, neg_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfiX-7JlVz3g"
      },
      "outputs": [],
      "source": [
        "for features, label in pos_ds.take(1):\n",
        "  print(\"Features:\\n\", features.numpy())\n",
        "  print()\n",
        "  print(\"Label: \", label.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxKa8G5TV1l0"
      },
      "outputs": [],
      "source": [
        "resampled_ds = tf.data.Dataset.sample_from_datasets([pos_ds, neg_ds], weights=[0.5, 0.5])\n",
        "resampled_ds = resampled_ds.batch(BATCH_SIZE).prefetch(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9T7r4lLV1rC"
      },
      "outputs": [],
      "source": [
        "for features, label in resampled_ds.take(1):\n",
        "  print(label.numpy().mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WG11DInV5Fg"
      },
      "outputs": [],
      "source": [
        "resampled_steps_per_epoch = np.ceil(2.0*neg/BATCH_SIZE)\n",
        "resampled_steps_per_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvvxfKnKV65c"
      },
      "outputs": [],
      "source": [
        "resampled_model = make_model()\n",
        "resampled_model.load_weights(initial_weights)\n",
        "\n",
        "# Reset the bias to zero, since this dataset is balanced.\n",
        "output_layer = resampled_model.layers[-1] \n",
        "output_layer.bias.assign([0])\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((val_features, val_labels)).cache()\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(2) \n",
        "\n",
        "resampled_history = resampled_model.fit(\n",
        "    resampled_ds,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=resampled_steps_per_epoch,\n",
        "    callbacks=[early_stopping],\n",
        "    validation_data=val_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x04qUmQRV8u2"
      },
      "outputs": [],
      "source": [
        "plot_metrics(resampled_history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of 351 GP - Models_balance.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}